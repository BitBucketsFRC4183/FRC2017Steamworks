import cv2
import numpy as np
from targetdata import TargetData

class BoilerStack:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self, networkTable):
        """initializes all values to presets or None if need to be set
        """
        self.targetData = TargetData()
        self.networkTable = networkTable
        
        self.__resize_image_width = 320.0
        self.__resize_image_height = 240.0
        self.__resize_image_interpolation = cv2.INTER_CUBIC

        self.resize_image_output = None

        self.__hsl_threshold_input = self.resize_image_output
        self.__hsl_threshold_hue = [51.798561151079134, 93.99317406143345]
        self.__hsl_threshold_saturation = [71.08812949640287, 255.0]
        self.__hsl_threshold_luminance = [36.690647482014384, 255.0]

        self.hsl_threshold_output = None

        self.__find_contours_input = self.hsl_threshold_output
        self.__find_contours_external_only = True

        self.find_contours_output = None

        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area = 20.0
        self.__filter_contours_min_perimeter = 0.0
        self.__filter_contours_min_width = 0.0
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 0.0
        self.__filter_contours_max_height = 1000.0
        self.__filter_contours_solidity = [0, 100]
        self.__filter_contours_max_vertices = 1000000.0
        self.__filter_contours_min_vertices = 0.0
        self.__filter_contours_min_ratio = 0.0
        self.__filter_contours_max_ratio = 1000.0

        self.filter_contours_output = None
        
        self.lastCenterX = float('NaN')
        self.lastCenterY = float('NaN')
        self.lastDistance_inches = float('NaN')
        self.lastCenter_deg = float('NaN')


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """

        # Step HSL_Threshold0:
        self.__hsl_threshold_input = source0
        (self.hsl_threshold_output) = self.__hsl_threshold(self.__hsl_threshold_input, self.__hsl_threshold_hue, self.__hsl_threshold_saturation, self.__hsl_threshold_luminance)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsl_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.find_contours_output
        (self.filter_contours_output) = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)

        # Optionally draw the contours for debug
        # For now, just uncomment as needed
        #cv2.drawContours(source0, self.find_contours_output, -1, (0,255,0), 3)

        FOV_deg = 63.2 # Field of View in degrees Approximately and empirically determined

        # Find the bounding rectangles
        # Two types of rectangles, straight and rotated
        # Staight is always oriented to the image view
        # Rotated find the minimum area rectangle that may be oriented
        # at some angle (i.e, not aligned to screen)
        # In either case we can use the information to identify
        # our intended target
        detections = []        # List for items that have both angle and shape we want
        detectionType = []
        other = []            # List for other objects that have correct angle, but are wrong shape
        for cnt in self.filter_contours_output:

            # Straight rectangle thusly
            #x,y,w,h = cv2.boundingRect(cnt)

            # Minimum area rectangle (i.e., rotated)
            rect = cv2.minAreaRect(cnt)

            # Rectangle format is: ( center (x,y), (width, height), angle of rotation )
            x = rect[0][0]
            y = rect[0][1]
            w = rect[1][0]
            h = rect[1][1]
            angle_deg = abs(rect[2])
        
            # width and height also depend on angle to determine
            # orientation; angles near 0 we will accept the width
            # and height as-is, but near 90 we will swap the height
            # and width to keep things normalized
        
            if (angle_deg >= 85.0):
                w,h = h,w    # swap
                angle_deg -= 90.0
            
            # Objects large than certain sizes should be ignored complete
            # since they are likely reflections saturating the image
            # This may leave us with nothing to look at, but that is okay
            # as the image is useless at this point
            #
            # NOTE: Limits are based on empircal data of approx 9 inches
            # from the camera plane, computed as follows
            #   d ~ 1441.452/h --> h ~ 1441.452/d
            if (h >= 160): # Which also happens to be 1/2 of current resolution
                continue
            
            ratio = w / h

            rect = ((x,y),(w,h),angle_deg)
            
            # only accept detections that are with 5 degrees of level
            # and have the correct aspect ratio (which is tricky)
            #
            # Aspect ratio discussion:
            #
            #   The boiler stack has two stripes of different sizes
            #   on a curved surface. The height is easily identified
            #   based on 4" tape, 4" gap, and 2" tape.
            #
            #   However, the width is only approximate as the retro tape
            #   will not reflect all the way through the curve. Despite this
            #   we can use the boiler stack width as an upper limit and then
            #   set the tolerance based on a reasonable lower limit (which
            #   depends on how much light we use as much as the angles.
            #   
            #   So: w / h
            #   Top stripe <= 15 / 4 =  3.75
            #   Bottom strip <= 15 / 2 = 7.5
            #
            #   If we assume that we might only see the middle 2/3rds then
            #   a reasonble limit would be:
            #       Top:      2.5 <= x <= 3.75
            #       Bottom:   5   <= x <= 7.5
            #
            if (angle_deg <= 5.0):
                if ((2.5 <= ratio <= 3.75) or (5 <= ratio <= 7.5)):

                    detections.append(rect)
                    detectionType.append('Strong')
                    
                    # Identify angled bounding box and display
                    box = cv2.boxPoints(rect)
                    box = np.int0(box)
                    
                    # Draw strong candidate in green
                    cv2.drawContours(source0,[box],0,(0,255,0),2)
                    
                else:
                    # Save this off just in case we need to build a
                    # faux detection from the pieces of smaller objects
                    other.append(rect)
                    
                    # Identify angled bounding box and display
                    box = cv2.boxPoints(rect)
                    box = np.int0(box)
                    
                    # Draw these pieces in red
                    cv2.drawContours(source0,[box],0,(0,0,255),2)
 
        # Insert reconstructed target logic here if needed

        # If there are any detections we need to sift through them for a pair
        # that is on the same horizon but below the highest expected point on the image
        numDetections = len(detections)
        

        # If there are more than 2 candidates we need to remove items that don't
        # correspond to each other.
        #
        # In particular, candidates need to be within the correct ratios
        # to each other and on the same horizon (again within our 5 degree tolerance)
        #
        observations = []
        observationsVerified = False
        if (numDetections > 2):
            i = 0
            for di in detections:
                i = i + 1
                xi = di[0][0]
                yi = di[0][1]
                wi = di[1][0]
                hi = di[1][1]
                
                for dj in detections[i:]:
                    xj = dj[0][0]
                    yj = dj[0][1]
                    wj = dj[1][0]
                    hj = dj[1][1]

                    # We care about top/bottom: the top target should appear
                    # twice as high as the bottom target and be centered
                    # within 5 degrees and be spaced approximately the same
                    # as the height of the top target.
                    
                    # determine which is on top
                    if (yi < yj):
                        top = di
                        topx = xi
                        topy = yi
                        topw = wi
                        toph = hi
                        
                        bot = dj
                        botx = xj
                        boty = yj
                        botw = wj
                        both = hj
                    else:
                        top = dj
                        topx = xj
                        topy = yj
                        topw = wj
                        toph = hj
                        
                        bot = di
                        botx = xi
                        boty = yi
                        botw = wi
                        both = hi
                    
                    
                    # First top must be approximately 2x taller than bottom
                    # We will allow a 10% error (0.2 to 0.4 inches total) on 
                    # either side
                    if (1.8 <= toph/both <= 2.2):
                        # To be the correct target, the centers must be spaced 7"
                        # apart and within 5 degrees of vertical.
                        # Sum of top (4") and bottom (2") heights is  assumed 6"
                        inchh = (toph + both) / 6.0
                        deltay = abs(topy - boty)
                        if (6.5 <= (deltay/inchh) <= 7.5):  # 0.5 inch tolerance seems reasonable
                           # We cannot reliably define the width since we are never sure how much
                           # of the curved tape will reflect... all we can do is use pixel
                           # estimates based on known width of image and sassuming that
                           # the local area of the image is flat enough
                           deltax = abs(topx - botx)
                           errorx_deg = (deltax / 320.0) * FOV_deg
                           if (errorx_deg <= 5.0):
                               # This looks like the real thing
                               observations.append(top)
                               observations.append(bot)
                               observationsVerified = True
                               break;
                
                if (observations != []):
                    break
        else:
            observations = detections
                    
        
        numObservations = len(observations)
        
        # Draw thin line down center of screen
        cv2.line(source0,(320/2,0),(320/2,240),(255,0,0),1)
        
        nan = float('NaN')
        
        if (numObservations == 2):
            # Having exactly two (2) observations is the easy case
        
            # NOTE: If the observations were already verified there is no
            # need to recheck the ratios

            x1 = observations[0][0][0]
            y1 = observations[0][0][1]
            w1 = observations[0][1][0]
            h1 = observations[0][1][1]
            
            
            x2 = observations[1][0][0]
            y2 = observations[1][0][1]
            w2 = observations[1][1][0]
            h2 = observations[1][1][1]
            
            if (observationsVerified == False):
                    # determine which is on top
                    if (y1 < y2):
                        topx = x1
                        topy = y1
                        topw = w1
                        toph = h1
                        
                        botx = x2
                        boty = y2
                        botw = w2
                        both = h2
                    else:
                        topx = x2
                        topy = y2
                        topw = w2
                        toph = h2
                        
                        botx = x1
                        boty = y1
                        botw = w1
                        both = h1
                    
                    
                    # First top must be approximately 2x taller than bottom
                    # We will allow a 10% error (0.2 to 0.4 inches total) on 
                    # either side
                    if (1.8 <= toph/both <= 2.2):
                        # To be the correct target, the centers must be spaced 7"
                        # apart and within 5 degrees of vertical.
                        # Sum of top (4") and bottom (2") heights is  assumed 6"
                        inchh = (toph + both) / 6.0
                        deltay = abs(topy - boty)
                        if (6.5 <= (deltay/inchh) <= 7.5):  # 0.5 inch tolerance seems reasonable
                           # We cannot reliably define the width since we are never sure how much
                           # of the curved tape will reflect... all we can do is use pixel
                           # estimates based on known width of image and sassuming that
                           # the local area of the image is flat enough
                           deltax = abs(topx - botx)
                           errorx_deg = (deltax / 320.0) * FOV_deg
                           if (errorx_deg <= 5.0):
                               # This looks like the real thing
                               observationsVerified = True
            
            # If either the original check or the check above verified
            # the observation pair, then we can indicate high confidence
            # and provide data
            # Otherwise, there is probably something wrong with one or more
            # of the observations can we can't be certain which one to use
            # without guessing (e.g., we could assume that items closer to
            # the center might be the real target, but it would be just a
            # guess...albeit probably a good guess because initial positioning
            # should have gotten it close)
            if (observationsVerified == True):
                # Target confidence is high
                self.networkTable.putNumber("StackConfidence",1.0)
                
                centerX = (x1+x2)/2
                centerY = (y1+y2)/2

                sumh = (h1 + h2) # approx 6 inches                          
                radius = sumh / 12      # about 0.5"
                
                centerFraction = ((2.0*centerX)/320.0) - 1.0 # cam res is 320, avg & scale cancel
                center_deg = FOV_deg/2 * centerFraction
                self.networkTable.putNumber("StackCenterX",centerFraction)
                self.networkTable.putNumber("StackCenter_deg",center_deg)
    
                # Target center within radius if screen center will be green
                # otherwise yellow until center is beyond middle 1/3rd of FOV
                if (abs(320/2 - centerX) <= radius):
                    color = (0,255,0)
                elif (center_deg <= 20.0):
                    color = (0,255,255)
                else:
                    color = (0,0,255)
    
                cv2.circle(source0, (int(centerX), int(centerY)), int(radius), color, 2)
                
                self.lastCenterX = centerX
                self.lastCenterY = centerY
                self.lastDistance_inches = nan #distance_inches
                self.lastCenter_deg = center_deg
        
            else:
                # We simply don't have any good information to go on
                # I.e., in this case there were two observations that did not
                # correlate to the known parameters and it would have simply
                # been better if we only had one since now we don't know which
                # to pick; as explained, above, anything we attempt is just
                # a guess.

                self.networkTable.putNumber("StackConfidence",0.0)
                self.networkTable.putNumber("StackDistance_inches",nan)
                self.networkTable.putNumber("StackCenterX",nan)
                self.networkTable.putNumber("StackCenter_deg",nan)
                
                # Reset the last known values 
                self.lastCenterX = nan
                self.lastCenterY = nan
                self.lastDistance_inches = nan
                self.lastCenter_deg = nan


        else:
            self.networkTable.putNumber("StackConfidence",0.0)
            self.networkTable.putNumber("StackDistance_inches",nan)
            self.networkTable.putNumber("StackCenterX",nan)
            self.networkTable.putNumber("StackCenter_deg",nan)
            
            # Reset the last known values 
            self.lastCenterX = nan
            self.lastCenterY = nan
            self.lastDistance_inches = nan
            self.lastCenter_deg = nan
            
        return (self.find_contours_output, self.filter_contours_output)

    @staticmethod
    def __resize_image(input, width, height, interpolation):
        """Scales and image to an exact size.
        Args:
            input: A numpy.ndarray.
            Width: The desired width in pixels.
            Height: The desired height in pixels.
            interpolation: Opencv enum for the type fo interpolation.
        Returns:
            A numpy.ndarray of the new size.
        """
        return cv2.resize(input, ((int)(width), (int)(height)), 0, 0, interpolation)

    @staticmethod
    def __hsl_threshold(input, hue, sat, lum):
        """Segment an image based on hue, saturation, and luminance ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max luminance.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HLS)
        return cv2.inRange(out, (hue[0], lum[0], sat[0]),  (hue[1], lum[1], sat[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        im2, contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        return contours

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        output = []
        for contour in input_contours:
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            output.append(contour)
        return output



